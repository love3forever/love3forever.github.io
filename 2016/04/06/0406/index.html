<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="Python学习">




  <meta name="keywords" content="爬虫 DouBan,">




  <link rel="alternate" href="/default" title="搬砖工的日常">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.4.x">



<link rel="canonical" href="http://eclipsesv.com/2016/04/06/0406/">


<meta name="description" content="又是一个雷雨交加的夜晚，不知道从什么时候开始喜欢上了这种天气。前段时间一直在研究Python的一个HTTP2.0客户端Hyper，没想到竟喜欢上了Python。这几天也是挤时间学习，看了《笨办法学Python》和《Head First Python》之后，想就从爬虫开始实践一把。">
<meta name="keywords" content="爬虫 DouBan">
<meta property="og:type" content="article">
<meta property="og:title" content="Python学习">
<meta property="og:url" content="http://eclipsesv.com/2016/04/06/0406/index.html">
<meta property="og:site_name" content="搬砖工的日常">
<meta property="og:description" content="又是一个雷雨交加的夜晚，不知道从什么时候开始喜欢上了这种天气。前段时间一直在研究Python的一个HTTP2.0客户端Hyper，没想到竟喜欢上了Python。这几天也是挤时间学习，看了《笨办法学Python》和《Head First Python》之后，想就从爬虫开始实践一把。">
<meta property="og:locale" content="zh-cn">
<meta property="og:updated_time" content="2017-06-15T06:38:30.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python学习">
<meta name="twitter:description" content="又是一个雷雨交加的夜晚，不知道从什么时候开始喜欢上了这种天气。前段时间一直在研究Python的一个HTTP2.0客户端Hyper，没想到竟喜欢上了Python。这几天也是挤时间学习，看了《笨办法学Python》和《Head First Python》之后，想就从爬虫开始实践一把。">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.4.x">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">





<script>
  var CONFIG = {
    search: true,
    searchPath: "/search.xml",
    fancybox: true,
    toc: true,
  }
</script>




  



    <title> Python学习 · 搬砖工的日常 </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">搬砖工的日常</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            Home
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            Archives
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            Tags
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            Categories
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">搬砖工的日常</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
      
        <li class="menu-search">
          <form>
            <i class="iconfont icon-search" id="open-search"></i>
            <input type="text" class="search-input" id="search-input">
            <i class="iconfont icon-close" id="close-search"></i>
          </form>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Python学习
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2016年4月6日
        </span>
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#获取代理IP"><span class="toc-text">获取代理IP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实时消费Proxy"><span class="toc-text">实时消费Proxy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#豆瓣API实践"><span class="toc-text">豆瓣API实践</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#下步计划"><span class="toc-text">下步计划</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p>又是一个雷雨交加的夜晚，不知道从什么时候开始喜欢上了这种天气。<br>前段时间一直在研究Python的一个HTTP2.0客户端<a href="https://github.com/Lukasa/hyper" target="_blank" rel="noopener">Hyper</a>，没想到竟喜欢上了Python。这几天也是挤时间学习，看了<a href="https://book.douban.com/subject/26264642/" target="_blank" rel="noopener">《笨办法学Python》</a>和<a href="https://book.douban.com/subject/5310233/" target="_blank" rel="noopener">《Head First Python》</a>之后，想就从爬虫开始实践一把。<br><a id="more"></a><br>在多次尝试抓取网页内容之后，发现需要学的东西还挺多，Python基础的库urllib、requests这些，另外这次实践发现正则表达式也是十分重要。需要多加努力掌握才是。<br>在学习过程中，主要学会了使用浏览器Cookie、设置请求Header、随机更换Proxyhost这些东西来将爬虫伪装为浏览器。下面就直接放上通用性比较强点的代码吧。</p>
<h2 id="获取代理IP"><a href="#获取代理IP" class="headerlink" title="获取代理IP"></a>获取代理IP</h2><p>通过<a href="http://www.xicidaili.com" target="_blank" rel="noopener">http://www.xicidaili.com</a>这个网站可以实时获取到可用的代理服务器地址和端口，将其加入到一个队列，这里我是直接把他放在Redis的队列中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">#-*- coding: UTF-8 -*- </span><br><span class="line">import urllib2</span><br><span class="line">import redis</span><br><span class="line">from BeautifulSoup import BeautifulSoup</span><br><span class="line">class Proxy_queue:</span><br><span class="line">    def __init__(self, addr, p):</span><br><span class="line">        print &quot;链接数据库&quot;</span><br><span class="line">        self.r = redis.StrictRedis(host=addr,port=int(p),db=0)</span><br><span class="line">        self.listname=&quot;proxylist&quot;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    def set_proxy(self):</span><br><span class="line">        for page in range(1,10):</span><br><span class="line">            print page</span><br><span class="line">            url = &apos;http://www.xicidaili.com/nn/%s&apos; %page</span><br><span class="line">            user_agent = &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36&quot;</span><br><span class="line">            request = urllib2.Request(url)</span><br><span class="line">            request.add_header(&quot;User-Agent&quot;, user_agent)</span><br><span class="line">            content = urllib2.urlopen(request)</span><br><span class="line">            soup = BeautifulSoup(content)</span><br><span class="line">            trs = soup.find(&apos;table&apos;, &#123;&quot;id&quot;:&quot;ip_list&quot;&#125;).findAll(&apos;tr&apos;)</span><br><span class="line">            for tr in trs[1:]:</span><br><span class="line">                tds = tr.findAll(&apos;td&apos;)</span><br><span class="line">                ip = tds[2].text.strip()</span><br><span class="line">                port = tds[3].text.strip()</span><br><span class="line">                protocol = tds[6].text.strip()</span><br><span class="line">                if protocol == &apos;HTTP&apos; or protocol == &apos;HTTPS&apos;:</span><br><span class="line">                    try:</span><br><span class="line">                        self.r.lpush(self.listname,ip+&quot;:&quot;+port)</span><br><span class="line">                        print &apos;%s://%s:%s&apos; % (protocol, ip, port)</span><br><span class="line">                    except Exception, e:</span><br><span class="line">                        print str(e)</span><br><span class="line">                    else:</span><br><span class="line">                        pass</span><br><span class="line">                    finally:</span><br><span class="line">                        pass</span><br><span class="line">    def get_proxy(self):</span><br><span class="line"></span><br><span class="line">        if self.r:</span><br><span class="line">            if self.r.llen(self.listname) == 0:</span><br><span class="line">                print &quot;实时获取最新代理，请稍后......&quot;</span><br><span class="line">                self.set_proxy()</span><br><span class="line">                print &quot;完成最新代理的爬取！&quot;</span><br><span class="line">            return self.r.rpop(self.listname)</span><br></pre></td></tr></table></figure></p>
<h2 id="实时消费Proxy"><a href="#实时消费Proxy" class="headerlink" title="实时消费Proxy"></a>实时消费Proxy</h2><p>通过上边的方法获取到的代理服务器，暂时存放在Redis队列中，在用的时候可以通过下边的方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#encoding=utf8</span><br><span class="line">import urllib</span><br><span class="line">import socket</span><br><span class="line">from proxy_set import Proxy_queue</span><br><span class="line">import sys</span><br><span class="line">default_encoding = &apos;utf-8&apos;</span><br><span class="line">if sys.getdefaultencoding() != default_encoding:</span><br><span class="line">    reload(sys)</span><br><span class="line">    sys.setdefaultencoding(default_encoding)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">socket.setdefaulttimeout(3)</span><br><span class="line">url = &quot;http://ip.chinaz.com/getip.aspx&quot;</span><br><span class="line"></span><br><span class="line">oknum=1</span><br><span class="line">try:</span><br><span class="line">    queue = Proxy_queue(&quot;ip&quot;,port)</span><br><span class="line">except Exception, e:</span><br><span class="line">    print str(e)</span><br><span class="line">else:</span><br><span class="line">    pass</span><br><span class="line">finally:</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">if queue:</span><br><span class="line">    while True:</span><br><span class="line">        try:</span><br><span class="line">            proxy_host=&quot;http://&quot;+queue.get_proxy()</span><br><span class="line">            proxy=&#123;&quot;http&quot;:proxy_host&#125;</span><br><span class="line">            res = urllib.urlopen(url,proxies=proxy).read()</span><br><span class="line">            print str(oknum)+ res</span><br><span class="line">            oknum+=1</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print proxy</span><br><span class="line">            print e</span><br><span class="line">            continue</span><br></pre></td></tr></table></figure></p>
<h2 id="豆瓣API实践"><a href="#豆瓣API实践" class="headerlink" title="豆瓣API实践"></a>豆瓣API实践</h2><p>通过<a href="https://developers.douban.com/wiki/?title=api_v2" target="_blank" rel="noopener">豆瓣官方提供的API</a>可以获取到很多信息，可以满足个人建站的需求，我自己也尝试了一下，利用这些API获取电影、图书和音乐分类信息，得到的数据都是JSON格式的，直接放在MongoDB中很是方便。<br>这部分代码我直接放在了我的<a href="https://github.com/wangmengcn/DouBan_API_DEV" target="_blank" rel="noopener">Github</a>上。</p>
<h2 id="下步计划"><a href="#下步计划" class="headerlink" title="下步计划"></a>下步计划</h2><p>现在通过豆瓣API基本上获取到了电影、图书和音乐分类主页上类别的数据，下一步打算研究一下Flask框架，完成一个小网站，把这些数据当做基础数据用起来。</p>

      
    </div>

    
      
      



      
      
  <div class="post-reward">
    <input type="checkbox" name="reward" id="reward" hidden>
    <label class="reward-button" for="reward">赞赏支持</label>
    <div class="qr-code">
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="https://eclipsesv.com/pics/wpay.jpg" title="wechat">
        </label>
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="https://eclipsesv.com/pics/apay.jpg" title="alipay">
        </label>
      
    </div>
  </div>

    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/爬虫-DouBan/">爬虫 DouBan</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/04/22/0422/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">硕士论文致谢</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2016/03/25/0325/">
        <span class="next-text nav-default">213</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://eclipse-sv.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
  </div>


        </div>  
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:eclipse_sv@163.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/love3forever" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
    
    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">eclipsesv</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  

  
  <script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://eclipsesv.com/2016/04/06/0406/';
        this.page.identifier = '2016/04/06/0406/';
        this.page.title = 'Python学习';
    };
    (function() {
    var d = document, s = d.createElement('script');

    s.src = '//eclipse-sv.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();  
  </script>

  




    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.4.x"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.4.x"></script>

    
  <script type="text/html" id="search-result">
    <article class="post">
      <header class="post-header">
        <h1 class="post-title">
          <a href="$url$" class="post-link">
            $title$
          </a>
        </h1>
      </header>
      <div class="post-content">
        $content$
        <div class="read-more">
          <a href="$url$" class="read-more-link">
            阅读更多
          </a>
        </div>
      </div>
    </article>
  </script>
  <script type="text/html" id="no-search-result">
    <div class="no-result">
      <h2>No result found!</h2>
    </div>
  </script>
  <script type="text/javascript" src="/js/src/search.js?v=2.4.x"></script>

  </body>
</html>
